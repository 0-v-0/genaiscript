{"docstore/data":{"0122bb6f-fecc-4a80-b9c2-a093667bcff4":{"indexId":"0122bb6f-fecc-4a80-b9c2-a093667bcff4","nodesDict":{"acfb3ae8-985c-43bd-8e03-ff55da9fe781":{"id_":"acfb3ae8-985c-43bd-8e03-ff55da9fe781","metadata":{"filename":"src/rag/markdown.md"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/rag/markdown.md","metadata":{"filename":"src/rag/markdown.md"},"hash":"w9AN5bXv36/+I35YKq2YGqmt8Vtkubu9nUV0M20rYFM="}},"hash":"bJ/xgx98e3r+35YJ/j5JwTiroSegBJKG4CrrGdT5O2A=","text":"What is Markdown? Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world’s most popular markup languages. Using Markdown is different than using a WYSIWYG editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn’t like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different. For example, to denote a heading, you add a number sign before it (e.g., # Heading One). Or to make a phrase bold, you add two asterisks before and after it (e.g., **this text is bold**). It may take a while to get used to seeing Markdown syntax in your text, especially if you’re accustomed to WYSIWYG applications. The screenshot below shows a Markdown file displayed in the Visual Studio Code text editor.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"162b14c7-4f10-43c7-bcf9-ae844b4b5b89":{"id_":"162b14c7-4f10-43c7-bcf9-ae844b4b5b89","metadata":{"filename":"src/rag/loremipsum.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/rag/loremipsum.pdf","metadata":{"filename":"src/rag/loremipsum.pdf"},"hash":"Oir1qj5oGCxG9AN7ZPyI8mKlQYk/2naOUv/yWAHCZpc="}},"hash":"lIoM2CuyRI70wTy/60T0h+wZszLQ1z8YODbP49hHYQA=","text":"Lorem Ipsum \r\n\"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci \r\nvelit... \" \r\n\"There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is pain... \" \r\n \r\nWhat is Lorem Ipsum? Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been \r\nthe industry's standard dummy text ever since the 1500s, when an unknown printer took a galley \r\nof type and scrambled it to make a type specimen book. It has survived not only five centuries, but \r\nalso the leap into electronic typesetting, remaining essentially unchanged. It was popularised in \r\nthe  1960s  with  the  release  of  Letraset  sheets  containing  Lorem  Ipsum  passages,  and  more \r\nrecently  with  desktop  publishing  software  like Aldus  PageMaker  including  versions  of  Lorem \r\nIpsum. Why do we use it? It is a long established fact that a reader will be distracted by the readable content of a page when \r\nlooking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution \r\nof letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default \r\nmodel text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various \r\nversions have evolved over the years, sometimes by accident, sometimes on purpose (injected \r\nhumour and the like). Where does it come from? Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical \r\nLatin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor \r\nat  Hampden-Sydney  College  in  Virginia,  looked  up  one  of  the  more  obscure  Latin  words, \r\nconsectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical \r\nliterature,  discovered  the  undoubtable  source. Lorem  Ipsum  comes  from  sections  1.10.32  and \r\n1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written \r\nin 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The \r\nfirst line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32. The standard  chunk  of  Lorem  Ipsum  used  since  the  1500s  is  reproduced  below  for  those \r\ninterested. Sections 1.10.32  and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are \r\nalso  reproduced  in  their  exact  original  form,  accompanied  by  English  versions  from the  1914 \r\ntranslation by H. Rackham. Where can I get some? There are many variations of passages of Lorem Ipsum available, but the majority have suffered \r\nalteration in some form, by injected humour, or randomised words which don't look even slightly \r\nbelievable. If you  are going  to use  a passage of Lorem Ipsum, you  need to be  sure there isn't \r\nanything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet \r\ntend to repeat predefined chunks as necessary, making this the first true generator on the Internet.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"dc172e56-0e7b-4440-93f5-f6f568ab9932":{"id_":"dc172e56-0e7b-4440-93f5-f6f568ab9932","metadata":{"filename":"src/rag/loremipsum.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/rag/loremipsum.pdf","metadata":{"filename":"src/rag/loremipsum.pdf"},"hash":"NBLfE10YIcKF/wdiDwgwz1ELrWLQkvNNjdvFiXVm4E0="}},"hash":"cfVt2fsgBI3W3pIIIQrGL25xJ/mnOa4nAV85NN04SRI=","text":"It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, \r\nto generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always \r\nfree from repetition, injected humour, or non-characteristic words etc.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7c058fc1-b9ed-4f57-bf3d-8371e08640a5":{"id_":"7c058fc1-b9ed-4f57-bf3d-8371e08640a5","metadata":{"filename":"src/rag/Document.docx"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/rag/Document.docx","metadata":{"filename":"src/rag/Document.docx"},"hash":"IMJRu/vF6H9tlzKfyd/OI71zAoSKZCZR/LSYmtk2F4U="}},"hash":"G9czA7w1lol29UD/M2US8r88oUShD1YxDEaT3TYT11c=","text":"Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983,[9] under the name Multi-Tool Word for Xenix systems.[10][11][12] Subsequent versions were later written for several other platforms including: IBM PCs running DOS (1983), Apple Macintosh running the Classic Mac OS (1985), AT&T UNIX PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1990), macOS (2001), Web browsers (2010), iOS (2014) and Android (2015). Using Wine, versions of Microsoft Word before 2013 can be run on Linux. Commercial versions of Word are licensed as a standalone product or as a component of Microsoft 365 suite of software, which can be purchased either with a perpetual license or as part of a Microsoft 365 subscription, respectively.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"4cb47753-6ff4-4d4a-b031-57cb71bc56bb":{"id_":"4cb47753-6ff4-4d4a-b031-57cb71bc56bb","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"RnCa3p6q/vm/WLnGdLRT/m4yOJyyeuNy7n5THSmT7cw="}},"hash":"9tKvp1AlP8nBFnSYBuBnoyFh5KQApcfm0ld69zeIfyY=","text":"Model Card (Orca-Mistral) \r\nLink: microsoft/Orca-Mistral · Hugging Face \r\nOrca-Mistral is built for research purposes only and provides a single turn response in tasks \r\nsuch as reasoning over user given data, reading comprehension, math problem solving and text \r\nsummarization. The model is designed to excel particularly in reasoning. Note that: \r\n1. This is a research model, intended to show that we can use capable models and \r\ncomplex workflows (advanced prompts, multiple calls) to create synthetic data that can \r\nteach Small Language Models (SLMs) new capabilities. We chose reasoning because it \r\nis a widely useful capability that SLMs lack. 2. The model is not optimized for chat and has not been trained with RLHF or DPO. It is \r\nbest used after being finetuned for chat or for a specific task. 3. Beyond reasoning, the model inherits capabilities and limitations of its base (Mistral-\r\n7b). We have already seen that the benefits of the Orca training can be applied to other \r\nbase model too. We make Orca-Mistral's weights publicly available to support further research on the \r\ndevelopment, evaluation, and alignment of SLMs. What is Orca-Mistral’s intended use(s)? • Orca-Mistral is built for research purposes only. • The main purpose is to allow the research community to assess its abilities and to \r\nprovide a foundation for building better frontier models. How was Orca-Mistral evaluated? [TODO: Add main eval result] \r\n• Orca-Mistral has been evaluated on a large number of tasks ranging from reasoning to \r\ngrounding and safety. Model Details \r\nOrca-Mistral is a finetuned version of Mistral-7b. Orca-Mistral’s training data is a synthetic \r\ndataset that was created to enhance the small model’s reasoning abilities. All synthetic training \r\ndata was moderated using the Microsoft Azure content filters. More details about the model can \r\nbe found in the Orca 2 paper. Please refer to Mistral-7b technical report for details on the model architecture. License \r\nOrca-Mistral is licensed under the MIT License. Bias, Risks, and Limitations","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"641e937e-5084-4fcf-b36c-cd869749a3bc":{"id_":"641e937e-5084-4fcf-b36c-cd869749a3bc","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"MU3y8DVQw9lZAF8G1+rUYrBrMAqwOFWgp4Cy31pvALE="}},"hash":"5Ea7urjYHKms4zbRQ5QMhyIBJJxP08iEDBH+roz3Hpg=","text":"Orca-Mistral, built upon the Mistral-7b, retains many of its limitations, as well as the common \r\nlimitations of other large language models or limitation caused by its training process, \r\nincluding: \r\nData Biases: Large language models, trained on extensive data, can inadvertently carry biases \r\npresent in the source data. Consequently, the models may generate outputs that could be \r\npotentially biased or unfair. Lack of Contextual Understanding: Despite their impressive capabilities in language \r\nunderstanding and generation, these models exhibit limited real-world understanding, resulting \r\nin potential inaccuracies or nonsensical responses. Lack of Transparency: Due to the complexity and size, large language models can act as “black \r\nboxes”, making it difficult to comprehend the rationale behind specific outputs or decisions. We \r\nrecommend reviewing transparency notes from Azure for more information. Content Harms: There are various types of content harms that large language models can \r\ncause. It is important to be aware of them when using these models, and to take actions to \r\nprevent them. It is recommended to leverage various content moderation services provided by \r\ndifferent companies and institutions. On an important note, we hope for better regulations and \r\nstandards from government and technology leaders around content harms for AI technologies \r\nin future. We value and acknowledge the important role that research and open source \r\ncommunity can play in this direction. Hallucination: It is important to be aware and cautious not to entirely rely on a given language \r\nmodel for critical decisions or information that might have deep impact as it is not obvious how \r\nto prevent these models from fabricating content. Moreover, it is not clear whether small \r\nmodels may be more susceptible to hallucination in ungrounded generation use cases due to \r\ntheir smaller sizes and hence reduced memorization capacities. This is an active research topic \r\nand we hope there will be more rigorous measurement, understanding and mitigations around \r\nthis topic. Potential for Misuse: Without suitable safeguards, there is a risk that these models could be \r\nmaliciously used for generating disinformation or harmful content. Data Distribution: Orca-Mistral’s performance is likely to correlate strongly with the \r\ndistribution of the tuning data. This correlation might limit its accuracy in areas \r\nunderrepresented in the training dataset such as math, coding, and reasoning. System messages: Orca-Mistral demonstrates variance in performance depending on the \r\nsystem instructions. Additionally, the stochasticity introduced by the model size may lead to \r\ngeneration of non-deterministic responses to different system instructions. Zero-Shot Settings: Orca-Mistral was trained on data that mostly simulate zero-shot settings. While the model demonstrate very strong performance in zero-shot settings, it does not show \r\nthe same gains of using few-shot learning compared to other, specially larger, models. Synthetic data: As Orca-Mistral is trained on synthetic data, it could inherit both the \r\nadvantages and shortcomings of the models and methods used for data generation. We posit \r\nthat Orca 2 benefits from the safety measures incorporated during training and safety guardrails \r\n(e.g., content filter) within the Azure OpenAI API. However, detailed studies are required for \r\nbetter quantification of such risks.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7ce16c71-a89a-4155-9eea-d09e5bb57036":{"id_":"7ce16c71-a89a-4155-9eea-d09e5bb57036","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"veBiXNIvPqf8FlqlkMl7ZvaFx4j4qtvMXtQMgsLbNe8="}},"hash":"ChzQh1lFB0XoD3115dqnt4ypBm6ku2Xn4i1sAEHlmqg=","text":"This model is solely designed for research settings, and its testing has only been carried out in \r\nsuch environments. It should not be used in downstream applications, as additional analysis is \r\nneeded to assess potential harm or bias in the proposed application. Getting started with Orca-Mistral \r\nInference with Hugging Face library \r\nimport torch \r\nimport transformers \r\n \r\nif torch.cuda.is_available(): \r\n    torch.set_default_device(\"cuda\") \r\nelse: \r\n    torch.set_default_device(\"cpu\") \r\n     \r\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\"microsoft/Orca-Mistral\", \r\ndevice_map='auto') \r\n \r\n# https://github.com/huggingface/transformers/issues/27132 \r\n# please use the slow tokenizer since fast and slow tokenizer produces different tokens \r\ntokenizer = transformers.AutoTokenizer.from_pretrained( \r\n        \"microsoft/Orca-Mistral\", \r\n        use_fast=False, \r\n    ) \r\n \r\nsystem_message = \"You are Orca, an AI language model created by Microsoft. You are a \r\ncautious assistant. You carefully follow instructions. You are helpful and harmless and you \r\nfollow ethical guidelines and promote positive behavior. \" \r\nuser_message = \"How can you determine if a restaurant is popular among locals or mainly \r\nattracts tourists, and why might this information be useful? \" \r\n \r\nprompt = \r\nf\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_\r\nend|>\\n<|im_start|>assistant\"","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ac47a6be-c035-4c0c-bb90-d6235eff6df7":{"id_":"ac47a6be-c035-4c0c-bb90-d6235eff6df7","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"aP4edTE/uvNqWphhe/KIBx+AfG8EDFBPtZRV/bPi3wU="}},"hash":"MWeC7B5AIJrXhUQkD24G8vDXOkeoXp2vwK+x1meab3E=","text":"inputs = tokenizer(prompt, return_tensors='pt') \r\noutput_ids = model.generate(inputs[\"input_ids\"],) \r\nanswer = tokenizer.batch_decode(output_ids)[0] \r\n \r\nprint(answer) \r\n \r\n# This example continues showing how to add a second turn message by the user to the \r\nconversation \r\nsecond_turn_user_message = \"Give me a list of the key points of your first answer. \" \r\n \r\n# we set add_special_tokens=False because we dont want to automatically add a bos_token \r\nbetween messages \r\nsecond_turn_message_in_markup = \r\nf\"\\n<|im_start|>user\\n{second_turn_user_message}<|im_end|>\\n<|im_start|>assistant\" \r\nsecond_turn_tokens = tokenizer(second_turn_message_in_markup, return_tensors='pt', \r\nadd_special_tokens=False) \r\nsecond_turn_input = torch.cat([output_ids, second_turn_tokens['input_ids']], dim=1) \r\n \r\noutput_ids_2 = model.generate(second_turn_input,) \r\nsecond_turn_answer = tokenizer.batch_decode(output_ids_2)[0] \r\n \r\nprint(second_turn_answer) \r\nSafe inference with Azure AI Content Safety \r\nThe usage of Azure AI Content Safety on top of model prediction is strongly encouraged and can \r\nhelp preventing some of content harms. Azure AI Content Safety is a content moderation \r\nplatform that uses AI to moderate content. By having Azure AI Content Safety on the output of \r\nOrca 2, the model output can be moderated by scanning it for different harm categories \r\nincluding sexual content, violence, hate, and self-harm with multiple severity levels and multi-\r\nlingual detection. import os \r\nimport math \r\nimport transformers \r\nimport torch","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"28b07e0b-e3a5-4e87-8f0c-587070a35a01":{"id_":"28b07e0b-e3a5-4e87-8f0c-587070a35a01","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"BuD6/rbIHecFf5nHCmC2hotZUIHDeORJL4miC7rd+ow="}},"hash":"bsxZsoGOmGY+KVebiWrp6OiP/sAk0SsIuXp7g1IAYZM=","text":"from azure.ai.contentsafety import ContentSafetyClient \r\nfrom azure.core.credentials import AzureKeyCredential \r\nfrom azure.core.exceptions import HttpResponseError \r\nfrom azure.ai.contentsafety.models import AnalyzeTextOptions \r\n \r\nCONTENT_SAFETY_KEY = os.environ[\"CONTENT_SAFETY_KEY\"] \r\nCONTENT_SAFETY_ENDPOINT = os.environ[\"CONTENT_SAFETY_ENDPOINT\"] \r\n \r\n# We use Azure AI Content Safety to filter out any content that reaches \"Medium\" threshold \r\n# For more information: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/ \r\ndef should_filter_out(input_text, threshold=4): \r\n    # Create an Content Safety client \r\n    client = ContentSafetyClient(CONTENT_SAFETY_ENDPOINT, \r\nAzureKeyCredential(CONTENT_SAFETY_KEY)) \r\n \r\n    # Construct a request \r\n    request = AnalyzeTextOptions(text=input_text) \r\n \r\n    # Analyze text \r\n    try: \r\n        response = client.analyze_text(request) \r\n    except HttpResponseError as e: \r\n        print(\"Analyze text failed. \") \r\n        if e.error: \r\n            print(f\"Error code: {e.error.code}\") \r\n            print(f\"Error message: {e.error.message}\") \r\n            raise \r\n        print(e) \r\n        raise","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ff6f846c-9d0d-4a80-a297-f691bd116746":{"id_":"ff6f846c-9d0d-4a80-a297-f691bd116746","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"YeHwSgDBPDnDyfJ9niKuGYsK38V5Frr+46AdKUHyJ3w="}},"hash":"yrMrHO5mdi9L9d6OLUA5pTtwG2n5YVgXnlDqRpLbNj8=","text":"categories = [\"hate_result\", \"self_harm_result\", \"sexual_result\", \"violence_result\"] \r\n    max_score = -math.inf \r\n    for category in categories: \r\n        max_score = max(max_score, getattr(response, category).severity) \r\n \r\n    return max_score >= threshold \r\n \r\nmodel_path = 'microsoft/Orca-Mistral' \r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \r\nmodel = transformers.AutoModelForCausalLM.from_pretrained(model_path) \r\nmodel.to(device) \r\n \r\ntokenizer = transformers.AutoTokenizer.from_pretrained( \r\n    model_path, \r\n    model_max_length=4096, \r\n    padding_side=\"right\", \r\n    use_fast=False, \r\n    add_special_tokens=False, \r\n) \r\n \r\nsystem_message = \"You are Orca, an AI language model created by Microsoft. You are a \r\ncautious assistant. You carefully follow instructions. You are helpful and harmless and you \r\nfollow ethical guidelines and promote positive behavior. \" \r\nuser_message = \"\\\" \\n :You can't just say, \\\"\\\"that's crap\\\"\\\" and remove it without gaining a \r\nconsensus. You already know this, based on your block history. —/ \\\" \\nIs the comment \r\nobscene? \\nOptions : Yes, No. \" \r\n \r\nprompt =  \r\nf\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_\r\nend|>\\n<|im_start|>assistant\" \r\n \r\ninputs = tokenizer(prompt, return_tensors='pt') \r\ninputs = inputs.to(device)","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9e79fb37-661d-495b-94c3-2433e3ffb878":{"id_":"9e79fb37-661d-495b-94c3-2433e3ffb878","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"src/raitools/Model-Card-Orca-Mistral.pdf","metadata":{"filename":"src/raitools/Model-Card-Orca-Mistral.pdf"},"hash":"+L2XQ9yReT7QSIsGOCJzVgdycWF3fBCcQL6uZN0GpHk="}},"hash":"h47w8951HAwwVUQkar1/naiETFHqHtBGb+Ph25UwpGU=","text":"output_ids = model.generate(inputs[\"input_ids\"], max_length=4096, do_sample=False, \r\ntemperature=0.0, use_cache=True) \r\nsequence_length = inputs[\"input_ids\"].shape[1] \r\nnew_output_ids = output_ids[:, sequence_length:] \r\nanswers = tokenizer.batch_decode(new_output_ids, skip_special_tokens=True) \r\nfinal_output = answers[0] if not should_filter_out(answers[0]) else \"[Content Filtered]\" \r\n \r\nprint(final_output) \r\nCitation \r\n@misc{mitra2023orca, \r\n      title={Orca 2: Teaching Small Language Models How to Reason},  \r\n      author={Arindam Mitra and Luciano Del Corro and Shweti Mahajan and Andres Codas and \r\nClarisse Simoes and Sahaj Agrawal and Xuxi Chen and Anastasia Razdaibiedina and Erik Jones \r\nand Kriti Aggarwal and Hamid Palangi and Guoqing Zheng and Corby Rosset and Hamed \r\nKhanpour and Ahmed Awadallah}, \r\n      year={2023}, \r\n      eprint={2311.11045}, \r\n      archivePrefix={arXiv}, \r\n      primaryClass={cs.AI} \r\n}","textTemplate":"","metadataSeparator":"\n","type":"TEXT"}},"type":"simple_dict"}}}