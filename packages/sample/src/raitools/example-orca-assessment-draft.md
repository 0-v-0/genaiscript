# Draft Impact Assessment for Orca Project

## Section 1: Project Information

### Project profile

**1.1** Project information:

- **Project Name:** Orca: Progressive Learning from Complex Explanation Traces of GPT-4
- **Group:** Microsoft Research
- **Point of contact:** Subhabrata Mukherjee (subhabrata.mukherjee@microsoft.com)

**Authors:** Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, Ahmed Awadallah
**Last updated:** June 5, 2023

**Contributors with affiliations:** Microsoft Research

### Project components and timeline

**1.2** The Orca project involves developing a 13-billion parameter model that learns to imitate the reasoning process of LFMs like GPT-4. The project has progressed through data collection, model training, and extensive evaluation. The team plans to present their findings in academic settings and potentially release a diff of the model weights in accordance with LLaMA's release policy. The timeline includes ongoing research, potential publication of findings, and public release of resources.

### Supporting material

**1.3** Supplementary information includes the project abstract, research papers, and evaluation datasets. Relevant R&CT records will be linked once available.

### Project goal and overview

**1.4** The goal of the Orca project is to enhance the capability of smaller AI models by learning from the complex outputs of larger foundation models like GPT-4. The project aims to address challenges in model imitation, task diversity, and rigorous evaluation. The team seeks to develop a model that not only imitates the style but also the reasoning process of LFMs.

### Relationship to products

**1.5** Orca is primarily a research project with potential implications for future Microsoft products. The technology could inform the development of more efficient AI models that retain the advanced reasoning capabilities of larger models.

## Section 2: Sharing

### What?

**2.1** Assets planned for sharing include the research paper, model weights (diff), and potentially the training code and datasets.

### Who?

**2.2** The sharing audience includes the research community, academic partners, and potentially the public if the model weights are released.

### Why?

**2.3** The goal of sharing is to contribute to the AI research community, foster collaboration, and showcase Microsoft's commitment to advancing AI responsibly.

## Section 3: Data information and considerations

### Data documentation

**3.1** Links to dataset onboarding records and additional data documentation will be provided.

### Data reflections

**3.2** The data used for training Orca includes outputs from GPT-4, which may reflect biases present in GPT-4's training data. The team has considered the impact of data diversity and scale on model performance.

## Section 4: Project impacts and limitations

### Impacts of sharing

**4.1** Successful sharing of Orca will advance the field of AI by demonstrating the potential of smaller models to perform complex reasoning tasks. It will also highlight Microsoft's role in responsible AI research.

### Known limitations

**4.2** Orca's limitations include potential biases inherited from GPT-4, limited contextual understanding, and the 'black box' nature of large models.

### Risks of sharing

**4.3** Malicious use of Orca could involve generating biased or harmful content. The most obvious abuse scenarios include misinformation and content manipulation.

**4.4** Unintentional misuse could occur if Orca is used in unsupported scenarios or by inexperienced users, leading to inaccurate outputs.

### Mitigations for immediate risks

**4.5** Mitigations include clear transparency documentation, such as a model card and a transparency note, and potentially gating the release through a form.

## Section 5: Thinking into the future

### Possible real-world uses

**5.1** Real-world uses of Orca could include enhancing smaller AI models for various applications, such as language translation, content generation, and decision support systems.

### Possible real-world misuses

**5.2** Potential misuses include leveraging Orca's capabilities for generating fake news, creating biased content, or automating deceptive practices.

### Stakeholders

**5.3** Stakeholders include the AI research community, users of AI systems, and society at large, which could be impacted by the advancements and potential misuses of AI technology.

### Intended Uses

**5.4** Intended use cases for Orca involve academic research, development of AI models, and potentially informing the creation of more responsible AI systems.

**5.5** Stakeholders most impacted include researchers, developers, and end-users who rely on AI for information and decision-making.

**5.6** Orca is best suited for stakeholders seeking to understand and improve the reasoning capabilities of AI models.

### Harms and mitigations

**5.7** Anticipated harms include the propagation of biases and misinformation. Mitigations involve rigorous evaluation, transparency in model capabilities, and the inclusion of diverse data and perspectives in training.
