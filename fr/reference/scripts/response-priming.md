Il est possible de fournir le dÃ©but de la rÃ©ponse du LLM (message `assistant`) dans le script.
Cela permet dâ€™orienter la rÃ©ponse du LLM vers une syntaxe ou un format spÃ©cifique.

Utilisez la fonction `assistant` pour fournir le texte de lâ€™assistant.

```js
$`List 5 colors. Answer with a JSON array. Do not emit the enclosing markdown.`

// help the LLM by starting the JSON array syntax
// in the assistant response
assistant(`[`)
```

<details>
  <summary>ğŸ‘¤ utilisateur</summary>

  ```markdown wrap
  List 5 colors. Answer with a JSON array. Do not emit the enclosing markdown.
  ```
</details>

<details open>
  <summary>ğŸ¤– assistant</summary>

  ```markdown wrap
  [
  ```
</details>

<details open>
  <summary>ğŸ¤– assistant</summary>

  ```markdown wrap
  "red",
  "blue",
  "green",
  "yellow",
  "purple"
  ]
  ```
</details>

:::caution
Cette fonctionnalitÃ© nâ€™est **pas** prise en charge par tous les modÃ¨les.
:::

### Comment Ã§a fonctionne ?

En interne, lors de lâ€™invocation du LLM, un message supplÃ©mentaire est ajoutÃ© Ã  la requÃªte comme si le LLM avait gÃ©nÃ©rÃ© ce contenu.

```json
{
  "messages": [
    ...,
    {
      "role": "assistant",
      "content": "[\n"
    }
  ]
}
```