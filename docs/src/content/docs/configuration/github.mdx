---
title: GitHub Models
sidebar:
  order: 2
---

import { FileTree } from "@astrojs/starlight/components";
import { Steps } from "@astrojs/starlight/components";
import { Tabs, TabItem } from "@astrojs/starlight/components";
import { Image } from "astro:assets";
import LLMProviderFeatures from "../../../components/LLMProviderFeatures.astro";

The [GitHub Models](https://github.com/marketplace/models) provider, `github`, allows running models through the GitHub Marketplace.
This provider is useful for prototyping and subject to [rate limits](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits)
depending on your subscription.

```js "github:"
script({ model: "github:openai/gpt-4o" });
```

### Codespace configuration

If you are running from a [GitHub Codespace](https://github.com/features/codespaces), the token is already configured for you...
It just works.

### GitHub Actions configuration

As of [April 2025](https://github.blog/changelog/2025-04-14-github-actions-token-integration-now-generally-available-in-github-models/),
you can use the GitHub Actions token (`GITHUB_TOKEN`) to call AI models directly inside your workflows.

<Steps>

<ol>

<li>

Ensure that the `models` permission is enabled in your workflow configuration.

```yaml title="genai.yml" "models: read"
permissions:
  models: read
```

</li>

<li>

Pass the `GITHUB_TOKEN` when running `genaiscript`

```yaml title="genai.yml" "GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}"
run: npx -y genaiscript run ...
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

</li>

</ol>

</Steps>

Read more in the [GitHub Documentation](https://docs.github.com/en/github-models/integrating-ai-models-into-your-development-workflow#using-ai-models-with-github-actions)

### Configuring with your own token

If you are not using GitHub Actions or Codespaces, you can use your own token to access the models.

<Steps>

<ol>

<li>

Create a [GitHub personal access token](https://github.com/settings/tokens/new).
The token should not have any scopes or permissions.

</li>

<li>

Update the `.env` file with the token.

```txt title=".env"
GITHUB_TOKEN=...
```

</li>

</ol>

</Steps>

To configure a specific model,

<Steps>

<ol>

<li>

Open the [GitHub Marketplace](https://github.com/marketplace/models) and find the model you want to use.

</li>

<li>

Copy the model name from the Javascript/Python samples

```js "Phi-3-mini-4k-instruct"
const modelName = "microsoft/Phi-3-mini-4k-instruct";
```

to configure your script.

```js "microsoft/Phi-3-mini-4k-instruct"
script({
  model: "github:microsoft/Phi-3-mini-4k-instruct",
});
```

</li>

</ol>

</Steps>

If you are already using `GITHUB_TOKEN` variable in your script and need a different one
for GitHub Models, you can use the `GITHUB_MODELS_TOKEN` variable instead.

### Organization Inference Point

By default, GitHub Models uses the current actor to run inference. You can specify an organization
in the `GITHUB_MODELS_ORG` environment to run inference on behalf of that organization instead.

```txt title=".env"
GITHUB_MODELS_ORG=my-org
```

The actor must be a member of the organization and have enabled models in the organization (see [documentation](https://docs.github.com/en/rest/models/embeddings#run-an-embedding-request-attributed-to-an-organization)).

### `o1-preview` and `o1-mini` models

Currently these models do not support streaming and
system prompts. GenAIScript handles this internally.

```js "github:openai/o1-mini"
script({
  model: "github:openai/o1-mini",
});
```

<LLMProviderFeatures provider="github" />
